"""
å–å®¶åˆ†çº§åˆ†ç±»æ¨¡å‹

ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œå–å®¶ç»†åˆ†ï¼Œç»“åˆä¸šåŠ¡è§„åˆ™å’Œæ•°æ®é©±åŠ¨çš„èšç±»åˆ†æï¼Œ
æ„å»ºå¤šç»´åº¦çš„å–å®¶åˆ†çº§ä½“ç³»ã€‚
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, silhouette_score
from sklearn.pipeline import Pipeline

import warnings
warnings.filterwarnings('ignore')

from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class SellerSegmentationModel:
    """å–å®¶åˆ†çº§åˆ†ç±»æ¨¡å‹ç±»"""
    
    def __init__(self, random_state: int = 42):
        """
        åˆå§‹åŒ–åˆ†çº§æ¨¡å‹
        
        Args:
            random_state: éšæœºç§å­
        """
        self.random_state = random_state
        self.scaler = StandardScaler()
        self.pca = PCA(n_components=0.95, random_state=random_state)
        self.clustering_models = {}
        self.classification_model = None
        self.feature_importance = None
        self.segmentation_results = None
        
        # ä¸šåŠ¡è§„åˆ™é…ç½®
        self.business_rules = {
            'high_value_threshold': {'revenue': 10000, 'orders': 50},
            'quality_threshold': {'rating': 4.0, 'positive_rate': 0.8},
            'risk_threshold': {'negative_rate': 0.3, 'risk_score': 0.7}
        }
        
    def fit_segmentation_model(self, seller_data: pd.DataFrame, 
                             segmentation_features: List[str] = None) -> Dict:
        """
        è®­ç»ƒå–å®¶åˆ†çº§æ¨¡å‹
        
        Args:
            seller_data: å–å®¶ç‰¹å¾æ•°æ®
            segmentation_features: ç”¨äºåˆ†çº§çš„ç‰¹å¾åˆ—è¡¨
            
        Returns:
            æ¨¡å‹è®­ç»ƒç»“æœ
        """
        logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒå–å®¶åˆ†çº§æ¨¡å‹...")
        
        # å‡†å¤‡æ•°æ®
        X, feature_names = self._prepare_segmentation_data(seller_data, segmentation_features)
        
        # æ–¹æ³•1: åŸºäºä¸šåŠ¡è§„åˆ™çš„åˆ†çº§
        business_segments = self._business_rule_segmentation(seller_data)
        
        # æ–¹æ³•2: K-meansèšç±»
        kmeans_segments = self._kmeans_segmentation(X, n_clusters=5)
        
        # æ–¹æ³•3: æ··åˆåˆ†çº§æ–¹æ³•
        hybrid_segments = self._hybrid_segmentation(seller_data, X, business_segments, kmeans_segments)
        
        # è¯„ä¼°åˆ†çº§æ•ˆæœ
        evaluation_results = self._evaluate_segmentation(X, hybrid_segments, feature_names)
        
        # ä¿å­˜ç»“æœ
        self.segmentation_results = {
            'business_segments': business_segments,
            'kmeans_segments': kmeans_segments,
            'hybrid_segments': hybrid_segments,
            'feature_names': feature_names,
            'evaluation': evaluation_results
        }
        
        # è®­ç»ƒåˆ†ç±»å™¨ç”¨äºæ–°å–å®¶é¢„æµ‹
        self._train_segment_classifier(X, hybrid_segments, feature_names)
        
        logger.info("âœ… å–å®¶åˆ†çº§æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        return self.segmentation_results
    
    def _prepare_segmentation_data(self, seller_data: pd.DataFrame, 
                                 feature_cols: List[str] = None) -> Tuple[np.ndarray, List[str]]:
        """å‡†å¤‡åˆ†çº§æ•°æ®"""
        
        # ç­›é€‰æ´»è·ƒå–å®¶
        active_sellers = seller_data[seller_data['total_orders'] > 0].copy()
        
        # é€‰æ‹©åˆ†çº§ç‰¹å¾
        if feature_cols is None:
            feature_cols = [
                'total_revenue', 'total_orders', 'avg_order_value', 'unique_products',
                'avg_review_score', 'positive_rate', 'negative_rate', 'total_reviews',
                'freight_ratio', 'avg_items_per_order', 'business_maturity_score',
                'risk_score', 'growth_potential_score'
            ]
        
        # ç­›é€‰å­˜åœ¨çš„ç‰¹å¾
        available_features = [col for col in feature_cols if col in active_sellers.columns]
        
        # å‡†å¤‡ç‰¹å¾çŸ©é˜µ
        X = active_sellers[available_features].fillna(0)
        
        # å¯¹æ•°å˜æ¢å¤„ç†åæ€åˆ†å¸ƒ
        log_transform_cols = ['total_revenue', 'total_orders', 'total_reviews']
        for col in log_transform_cols:
            if col in X.columns:
                X[col] = np.log1p(X[col])
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        
        logger.info(f"  ğŸ“Š åˆ†çº§æ•°æ®å‡†å¤‡å®Œæˆ: {X_scaled.shape[0]} ä¸ªå–å®¶, {X_scaled.shape[1]} ä¸ªç‰¹å¾")
        
        return X_scaled, available_features
    
    def _business_rule_segmentation(self, seller_data: pd.DataFrame) -> pd.Series:
        """åŸºäºä¸šåŠ¡è§„åˆ™çš„åˆ†çº§"""
        logger.info("  ğŸ¢ åº”ç”¨ä¸šåŠ¡è§„åˆ™åˆ†çº§...")
        
        segments = []
        
        for _, seller in seller_data.iterrows():
            # æ£€æŸ¥é«˜ä»·å€¼å–å®¶
            if (seller.get('total_revenue', 0) >= self.business_rules['high_value_threshold']['revenue'] and
                seller.get('total_orders', 0) >= self.business_rules['high_value_threshold']['orders'] and
                seller.get('avg_review_score', 0) >= self.business_rules['quality_threshold']['rating']):
                segments.append('Platinum')
                
            # æ£€æŸ¥ä¼˜è´¨å–å®¶
            elif (seller.get('total_revenue', 0) >= 5000 and
                  seller.get('avg_review_score', 0) >= 4.0 and
                  seller.get('positive_rate', 0) >= 0.75):
                segments.append('Gold')
                
            # æ£€æŸ¥æ ‡å‡†å–å®¶
            elif (seller.get('total_revenue', 0) >= 1000 and
                  seller.get('total_orders', 0) >= 10 and
                  seller.get('avg_review_score', 0) >= 3.5):
                segments.append('Silver')
                
            # æ£€æŸ¥é£é™©å–å®¶
            elif (seller.get('negative_rate', 0) >= self.business_rules['risk_threshold']['negative_rate'] or
                  seller.get('risk_score', 0) >= self.business_rules['risk_threshold']['risk_score']):
                segments.append('Risk')
                
            # å…¶ä»–å–å®¶
            else:
                segments.append('Bronze')
        
        segments_series = pd.Series(segments, index=seller_data.index)
        logger.info(f"    âœ… ä¸šåŠ¡è§„åˆ™åˆ†çº§å®Œæˆ: {segments_series.value_counts().to_dict()}")
        
        return segments_series
    
    def _kmeans_segmentation(self, X: np.ndarray, n_clusters: int = 5) -> pd.Series:
        """K-meansèšç±»åˆ†çº§"""
        logger.info(f"  ğŸ¯ K-meansèšç±»åˆ†çº§ (k={n_clusters})...")
        
        # è®­ç»ƒK-meansæ¨¡å‹
        kmeans = KMeans(n_clusters=n_clusters, random_state=self.random_state, n_init=10)
        cluster_labels = kmeans.fit_predict(X)
        
        # ä¿å­˜æ¨¡å‹
        self.clustering_models['kmeans'] = kmeans
        
        # è®¡ç®—èšç±»è´¨é‡
        silhouette = silhouette_score(X, cluster_labels)
        logger.info(f"    ğŸ“Š è½®å»“ç³»æ•°: {silhouette:.3f}")
        
        # ä¸ºèšç±»åˆ†é…ä¸šåŠ¡æ ‡ç­¾
        cluster_segments = self._assign_cluster_labels(X, cluster_labels, kmeans.cluster_centers_)
        
        return pd.Series(cluster_segments)
    
    def _assign_cluster_labels(self, X: np.ndarray, cluster_labels: np.ndarray, 
                             centers: np.ndarray) -> List[str]:
        """ä¸ºèšç±»åˆ†é…ä¸šåŠ¡å«ä¹‰çš„æ ‡ç­¾"""
        
        # è®¡ç®—æ¯ä¸ªèšç±»çš„ç‰¹å¾å‡å€¼
        cluster_profiles = []
        for i in range(len(centers)):
            cluster_mask = cluster_labels == i
            cluster_data = X[cluster_mask]
            
            profile = {
                'cluster_id': i,
                'size': len(cluster_data),
                'revenue_score': centers[i][0],  # å‡è®¾ç¬¬ä¸€ä¸ªç‰¹å¾æ˜¯æ”¶å…¥ç›¸å…³
                'quality_score': centers[i][4] if len(centers[i]) > 4 else 0,  # è¯„åˆ†ç›¸å…³
                'center': centers[i]
            }
            cluster_profiles.append(profile)
        
        # æ ¹æ®æ”¶å…¥å’Œè´¨é‡æ’åº
        cluster_profiles.sort(key=lambda x: (x['revenue_score'], x['quality_score']), reverse=True)
        
        # åˆ†é…æ ‡ç­¾
        tier_names = ['Platinum', 'Gold', 'Silver', 'Bronze', 'Basic']
        label_mapping = {}
        
        for i, profile in enumerate(cluster_profiles):
            label_mapping[profile['cluster_id']] = tier_names[min(i, len(tier_names)-1)]
        
        # æ˜ å°„æ ‡ç­¾
        segments = [label_mapping[label] for label in cluster_labels]
        
        return segments
    
    def _hybrid_segmentation(self, seller_data: pd.DataFrame, X: np.ndarray,
                           business_segments: pd.Series, kmeans_segments: pd.Series) -> pd.Series:
        """æ··åˆåˆ†çº§æ–¹æ³•"""
        logger.info("  ğŸ”„ æ··åˆåˆ†çº§æ–¹æ³•...")
        
        # ç»“åˆä¸šåŠ¡è§„åˆ™å’Œèšç±»ç»“æœ
        hybrid_segments = []
        
        for i, (business_seg, kmeans_seg) in enumerate(zip(business_segments, kmeans_segments)):
            # é«˜ä»·å€¼å–å®¶ä¼˜å…ˆä½¿ç”¨ä¸šåŠ¡è§„åˆ™
            if business_seg in ['Platinum', 'Gold']:
                hybrid_segments.append(business_seg)
            
            # é£é™©å–å®¶ä¼˜å…ˆæ ‡è®°
            elif business_seg == 'Risk':
                hybrid_segments.append('Risk')
            
            # å…¶ä»–æƒ…å†µç»¼åˆè€ƒè™‘
            else:
                # å¦‚æœèšç±»ç»“æœæ˜¾ç¤ºä¸ºé«˜ç­‰çº§ï¼Œä½†ä¸šåŠ¡è§„åˆ™ä¸æ˜¯ï¼Œè¿›è¡Œè°ƒæ•´
                if kmeans_seg in ['Platinum', 'Gold'] and business_seg in ['Bronze', 'Silver']:
                    hybrid_segments.append('Silver')  # ä¿å®ˆè°ƒæ•´
                else:
                    hybrid_segments.append(kmeans_seg)
        
        hybrid_series = pd.Series(hybrid_segments, index=seller_data.index)
        logger.info(f"    âœ… æ··åˆåˆ†çº§å®Œæˆ: {hybrid_series.value_counts().to_dict()}")
        
        return hybrid_series
    
    def _evaluate_segmentation(self, X: np.ndarray, segments: pd.Series, 
                             feature_names: List[str]) -> Dict:
        """è¯„ä¼°åˆ†çº§æ•ˆæœ"""
        logger.info("  ğŸ“Š è¯„ä¼°åˆ†çº§æ•ˆæœ...")
        
        # è®¡ç®—å„ç­‰çº§çš„ç‰¹å¾å‡å€¼
        X_df = pd.DataFrame(X, columns=feature_names, index=segments.index)
        X_df['segment'] = segments
        
        segment_profiles = X_df.groupby('segment').mean()
        
        # è®¡ç®—ç»„é—´å·®å¼‚
        segment_std = X_df.groupby('segment').std().mean(axis=1)
        
        # è®¡ç®—åˆ†ç¦»åº¦æŒ‡æ ‡
        total_variance = X_df[feature_names].var().sum()
        within_variance = X_df.groupby('segment')[feature_names].apply(
            lambda x: x.var().sum()
        ).mean()
        between_variance = total_variance - within_variance
        
        separation_ratio = between_variance / within_variance if within_variance > 0 else 0
        
        evaluation = {
            'segment_profiles': segment_profiles,
            'segment_sizes': segments.value_counts().to_dict(),
            'separation_ratio': separation_ratio,
            'within_variance': within_variance,
            'between_variance': between_variance
        }
        
        logger.info(f"    ğŸ“ˆ åˆ†ç¦»åº¦æ¯”ç‡: {separation_ratio:.3f}")
        
        return evaluation
    
    def _train_segment_classifier(self, X: np.ndarray, segments: pd.Series, 
                                feature_names: List[str]) -> None:
        """è®­ç»ƒåˆ†çº§åˆ†ç±»å™¨"""
        logger.info("  ğŸ¤– è®­ç»ƒåˆ†çº§åˆ†ç±»å™¨...")
        
        # ç¼–ç æ ‡ç­¾
        le = LabelEncoder()
        y_encoded = le.fit_transform(segments)
        
        # åˆ†å‰²è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=self.random_state, stratify=y_encoded
        )
        
        # è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
        rf_classifier = RandomForestClassifier(
            n_estimators=100, random_state=self.random_state, max_depth=10
        )
        rf_classifier.fit(X_train, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        y_pred = rf_classifier.predict(X_test)
        accuracy = (y_pred == y_test).mean()
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.DataFrame({
            'feature': feature_names,
            'importance': rf_classifier.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # ä¿å­˜æ¨¡å‹å’Œç»“æœ
        self.classification_model = {
            'model': rf_classifier,
            'label_encoder': le,
            'accuracy': accuracy,
            'feature_importance': feature_importance
        }
        
        logger.info(f"    ğŸ¯ åˆ†ç±»å™¨å‡†ç¡®ç‡: {accuracy:.3f}")
        logger.info(f"    ğŸ” Top 3 é‡è¦ç‰¹å¾: {list(feature_importance.head(3)['feature'])}")
    
    def predict_seller_segment(self, seller_features: pd.DataFrame) -> pd.Series:
        """é¢„æµ‹æ–°å–å®¶çš„åˆ†çº§"""
        if self.classification_model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ fit_segmentation_model")
        
        # å‡†å¤‡ç‰¹å¾
        X_new = seller_features[self.segmentation_results['feature_names']].fillna(0)
        
        # å¯¹æ•°å˜æ¢
        log_transform_cols = ['total_revenue', 'total_orders', 'total_reviews']
        for col in log_transform_cols:
            if col in X_new.columns:
                X_new[col] = np.log1p(X_new[col])
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.transform(X_new)
        
        # é¢„æµ‹
        predictions = self.classification_model['model'].predict(X_scaled)
        segment_labels = self.classification_model['label_encoder'].inverse_transform(predictions)
        
        return pd.Series(segment_labels, index=seller_features.index)
    
    def visualize_segmentation(self, seller_data: pd.DataFrame, save_plots: bool = True) -> None:
        """å¯è§†åŒ–åˆ†çº§ç»“æœ"""
        logger.info("ğŸ“Š ç”Ÿæˆåˆ†çº§å¯è§†åŒ–...")
        
        if self.segmentation_results is None:
            raise ValueError("è¯·å…ˆè¿è¡Œåˆ†çº§æ¨¡å‹")
        
        # è·å–åˆ†çº§ç»“æœ
        segments = self.segmentation_results['hybrid_segments']
        X = seller_data[self.segmentation_results['feature_names']].fillna(0)
        
        # 1. PCAé™ç»´å¯è§†åŒ–
        self._plot_pca_segments(X, segments, save_plots)
        
        # 2. ä¸šåŠ¡æŒ‡æ ‡å¯¹æ¯”
        self._plot_segment_comparison(seller_data, segments, save_plots)
        
        # 3. åˆ†çº§åˆ†å¸ƒ
        self._plot_segment_distribution(segments, save_plots)
        
        # 4. ç‰¹å¾é‡è¦æ€§
        if self.classification_model:
            self._plot_feature_importance(save_plots)
    
    def _plot_pca_segments(self, X: pd.DataFrame, segments: pd.Series, save_plots: bool) -> None:
        """PCAé™ç»´å¯è§†åŒ–"""
        # PCAé™ç»´åˆ°2D
        pca_2d = PCA(n_components=2, random_state=self.random_state)
        X_pca = pca_2d.fit_transform(StandardScaler().fit_transform(X))
        
        # åˆ›å»ºå¯è§†åŒ–
        fig = px.scatter(
            x=X_pca[:, 0], y=X_pca[:, 1], color=segments,
            title='å–å®¶åˆ†çº§PCAå¯è§†åŒ–',
            labels={'x': f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%})',
                   'y': f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%})'},
            color_discrete_map={
                'Platinum': '#FFD700', 'Gold': '#FFA500', 'Silver': '#C0C0C0',
                'Bronze': '#CD7F32', 'Basic': '#808080', 'Risk': '#FF0000'
            }
        )
        
        fig.update_layout(width=800, height=600)
        fig.show()
        
        if save_plots:
            fig.write_html('reports/pca_segmentation.html')
    
    def _plot_segment_comparison(self, seller_data: pd.DataFrame, segments: pd.Series, save_plots: bool) -> None:
        """åˆ†çº§ä¸šåŠ¡æŒ‡æ ‡å¯¹æ¯”"""
        # åˆå¹¶æ•°æ®
        plot_data = seller_data.copy()
        plot_data['segment'] = segments
        
        # å…³é”®æŒ‡æ ‡
        key_metrics = ['total_revenue', 'total_orders', 'avg_review_score', 'unique_products']
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å„åˆ†çº§å–å®¶ä¸šåŠ¡æŒ‡æ ‡å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        for i, metric in enumerate(key_metrics):
            ax = axes[i//2, i%2]
            
            # ç®±çº¿å›¾
            plot_data.boxplot(column=metric, by='segment', ax=ax)
            ax.set_title(f'{metric} åˆ†çº§å¯¹æ¯”')
            ax.set_xlabel('å–å®¶åˆ†çº§')
            ax.set_ylabel(metric)
            ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.show()
        
        if save_plots:
            plt.savefig('reports/segment_comparison.png', dpi=300, bbox_inches='tight')
    
    def _plot_segment_distribution(self, segments: pd.Series, save_plots: bool) -> None:
        """åˆ†çº§åˆ†å¸ƒå›¾"""
        segment_counts = segments.value_counts()
        
        fig = px.pie(
            values=segment_counts.values,
            names=segment_counts.index,
            title='å–å®¶åˆ†çº§åˆ†å¸ƒ',
            color_discrete_map={
                'Platinum': '#FFD700', 'Gold': '#FFA500', 'Silver': '#C0C0C0',
                'Bronze': '#CD7F32', 'Basic': '#808080', 'Risk': '#FF0000'
            }
        )
        
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(width=600, height=500)
        fig.show()
        
        if save_plots:
            fig.write_html('reports/segment_distribution.html')
    
    def _plot_feature_importance(self, save_plots: bool) -> None:
        """ç‰¹å¾é‡è¦æ€§å›¾"""
        if not self.classification_model:
            return
        
        importance_df = self.classification_model['feature_importance'].head(10)
        
        fig = px.bar(
            importance_df, x='importance', y='feature',
            orientation='h',
            title='å–å®¶åˆ†çº§æ¨¡å‹ç‰¹å¾é‡è¦æ€§ Top 10',
            labels={'importance': 'é‡è¦æ€§', 'feature': 'ç‰¹å¾'}
        )
        
        fig.update_layout(height=500, width=700)
        fig.show()
        
        if save_plots:
            fig.write_html('reports/feature_importance.html')
    
    def generate_segmentation_report(self, seller_data: pd.DataFrame) -> Dict:
        """ç”Ÿæˆåˆ†çº§æŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆåˆ†çº§æŠ¥å‘Š...")
        
        if self.segmentation_results is None:
            raise ValueError("è¯·å…ˆè¿è¡Œåˆ†çº§æ¨¡å‹")
        
        segments = self.segmentation_results['hybrid_segments']
        
        # å„åˆ†çº§çš„ä¸šåŠ¡è¡¨ç°
        segment_summary = seller_data.groupby(segments).agg({
            'total_revenue': ['count', 'sum', 'mean', 'median'],
            'total_orders': ['sum', 'mean'],
            'avg_review_score': 'mean',
            'positive_rate': 'mean',
            'unique_products': 'mean'
        }).round(2)
        
        # é‡å‘½ååˆ—
        segment_summary.columns = [
            'seller_count', 'total_gmv', 'avg_revenue', 'median_revenue',
            'total_orders', 'avg_orders', 'avg_rating', 'avg_positive_rate', 'avg_products'
        ]
        
        # è®¡ç®—è´¡çŒ®å æ¯”
        segment_summary['gmv_contribution'] = (
            segment_summary['total_gmv'] / segment_summary['total_gmv'].sum() * 100
        ).round(1)
        
        # ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ
        insights = self._generate_business_insights(segment_summary, segments)
        
        report = {
            'segment_summary': segment_summary,
            'insights': insights,
            'model_performance': {
                'accuracy': self.classification_model['accuracy'] if self.classification_model else None,
                'separation_ratio': self.segmentation_results['evaluation']['separation_ratio']
            }
        }
        
        return report
    
    def _generate_business_insights(self, segment_summary: pd.DataFrame, segments: pd.Series) -> Dict:
        """ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ"""
        insights = {}
        
        # é«˜ä»·å€¼å–å®¶æ´å¯Ÿ
        high_value_segments = ['Platinum', 'Gold']
        high_value_count = sum(segment_summary.loc[seg, 'seller_count'] 
                              for seg in high_value_segments if seg in segment_summary.index)
        high_value_gmv = sum(segment_summary.loc[seg, 'total_gmv'] 
                            for seg in high_value_segments if seg in segment_summary.index)
        
        insights['high_value_sellers'] = {
            'count': high_value_count,
            'percentage': high_value_count / len(segments) * 100,
            'gmv_contribution': high_value_gmv / segment_summary['total_gmv'].sum() * 100
        }
        
        # é£é™©å–å®¶æ´å¯Ÿ
        if 'Risk' in segment_summary.index:
            risk_info = segment_summary.loc['Risk']
            insights['risk_sellers'] = {
                'count': risk_info['seller_count'],
                'avg_rating': risk_info['avg_rating'],
                'revenue_impact': risk_info['gmv_contribution']
            }
        
        # æˆé•¿æœºä¼š
        if 'Silver' in segment_summary.index and 'Bronze' in segment_summary.index:
            growth_potential = (
                segment_summary.loc['Silver', 'seller_count'] + 
                segment_summary.loc['Bronze', 'seller_count']
            )
            insights['growth_opportunity'] = {
                'potential_sellers': growth_potential,
                'current_contribution': (
                    segment_summary.loc['Silver', 'gmv_contribution'] + 
                    segment_summary.loc['Bronze', 'gmv_contribution']
                )
            }
        
        return insights


# å·¥å…·å‡½æ•°
def run_segmentation_analysis(seller_data: pd.DataFrame) -> Tuple[SellerSegmentationModel, Dict]:
    """è¿è¡Œå®Œæ•´çš„åˆ†çº§åˆ†æ"""
    
    # åˆ›å»ºæ¨¡å‹
    model = SellerSegmentationModel()
    
    # è®­ç»ƒæ¨¡å‹
    results = model.fit_segmentation_model(seller_data)
    
    # ç”Ÿæˆå¯è§†åŒ–
    model.visualize_segmentation(seller_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = model.generate_segmentation_report(seller_data)
    
    return model, report


if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    print("ğŸ¯ å–å®¶åˆ†çº§åˆ†ç±»æ¨¡å‹æ¼”ç¤º")
    print("è¯·å…ˆè¿è¡Œæ•°æ®å¤„ç†ç®¡é“è·å–å–å®¶ç‰¹å¾æ•°æ®") 