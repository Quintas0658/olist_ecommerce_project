#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Olistæ•°æ®å¤„ç†ç®¡é“
æ•´åˆåŸå§‹æ•°æ®ï¼Œæ„å»ºå–å®¶ç”»åƒç‰¹å¾
"""

import pandas as pd
import numpy as np
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataPipeline:
    """æ•°æ®å¤„ç†ç®¡é“ç±»"""
    
    def __init__(self, data_path='data/'):
        self.data_path = data_path
        self.raw_data = {}
        self.seller_profile = None
        
    def load_raw_data(self):
        """åŠ è½½æ‰€æœ‰åŸå§‹æ•°æ®è¡¨"""
        logger.info("ğŸ“Š æ­£åœ¨åŠ è½½åŸå§‹æ•°æ®...")
        
        datasets = {
            'sellers': 'olist_sellers_dataset.csv',
            'orders': 'olist_orders_dataset.csv',
            'order_items': 'olist_order_items_dataset.csv',
            'reviews': 'olist_order_reviews_dataset.csv',
            'payments': 'olist_order_payments_dataset.csv',
            'products': 'olist_products_dataset.csv',
            'customers': 'olist_customers_dataset.csv',
            'category_translation': 'product_category_name_translation.csv'
        }
        
        for name, filename in datasets.items():
            try:
                self.raw_data[name] = pd.read_csv(f"{self.data_path}{filename}")
                logger.info(f"   âœ… {name}: {len(self.raw_data[name]):,} è®°å½•")
            except FileNotFoundError:
                # å°è¯•ä»archiveç›®å½•åŠ è½½
                try:
                    self.raw_data[name] = pd.read_csv(f"archive/{filename}")
                    logger.info(f"   âœ… {name}: {len(self.raw_data[name]):,} è®°å½• (ä»archiveåŠ è½½)")
                except FileNotFoundError:
                    logger.warning(f"   âŒ æœªæ‰¾åˆ° {filename}")
                    
        logger.info("âœ… åŸå§‹æ•°æ®åŠ è½½å®Œæˆ")
        return self.raw_data
    
    def build_seller_features(self):
        """æ„å»ºå–å®¶ç‰¹å¾ç”»åƒ"""
        logger.info("\nğŸ”§ æ­£åœ¨æ„å»ºå–å®¶ç‰¹å¾ç”»åƒ...")
        
        if not self.raw_data:
            self.load_raw_data()
            
        # 1. åŸºç¡€å–å®¶ä¿¡æ¯
        seller_profile = self.raw_data['sellers'].copy()
        
        # 2. é”€å”®ä¸šç»©æŒ‡æ ‡
        sales_features = self._build_sales_features()
        seller_profile = seller_profile.merge(sales_features, on='seller_id', how='left')
        
        # 3. å®¢æˆ·æ»¡æ„åº¦æŒ‡æ ‡
        satisfaction_features = self._build_satisfaction_features()
        seller_profile = seller_profile.merge(satisfaction_features, on='seller_id', how='left')
        
        # 4. è¿è¥æ•ˆç‡æŒ‡æ ‡
        efficiency_features = self._build_efficiency_features()
        seller_profile = seller_profile.merge(efficiency_features, on='seller_id', how='left')
        
        # 5. äº§å“å“ç±»æŒ‡æ ‡
        category_features = self._build_category_features()
        seller_profile = seller_profile.merge(category_features, on='seller_id', how='left')
        
        # 6. æ—¶é—´è¶‹åŠ¿æŒ‡æ ‡
        temporal_features = self._build_temporal_features()
        seller_profile = seller_profile.merge(temporal_features, on='seller_id', how='left')
        
        # 7. æ•°æ®æ¸…æ´—å’Œè¡ç”ŸæŒ‡æ ‡
        seller_profile = self._clean_and_derive_features(seller_profile)
        
        self.seller_profile = seller_profile
        
        logger.info(f"âœ… å–å®¶ç”»åƒæ„å»ºå®Œæˆ!")
        logger.info(f"   æ€»å–å®¶æ•°: {len(seller_profile):,}")
        logger.info(f"   æ´»è·ƒå–å®¶æ•°: {seller_profile['is_active'].sum():,}")
        logger.info(f"   ç‰¹å¾ç»´åº¦: {len(seller_profile.columns)}")
        
        return seller_profile
    
    def _build_sales_features(self):
        """æ„å»ºé”€å”®ä¸šç»©ç‰¹å¾"""
        logger.info("   ğŸ“ˆ æ„å»ºé”€å”®ä¸šç»©æŒ‡æ ‡...")
        
        orders = self.raw_data['orders']
        order_items = self.raw_data['order_items']
        
        # åˆå¹¶è®¢å•é¡¹ç›®å’Œè®¢å•ä¿¡æ¯
        order_details = order_items.merge(orders, on='order_id', how='left')
        
        # æŒ‰å–å®¶èšåˆé”€å”®æŒ‡æ ‡
        sales_metrics = order_details.groupby('seller_id').agg({
            'price': ['sum', 'mean', 'count'],
            'freight_value': ['sum', 'mean'],
            'order_id': 'nunique',
            'product_id': 'nunique'
        }).round(2)
        
        sales_metrics.columns = [
            'total_gmv', 'avg_order_value', 'total_items',
            'total_freight', 'avg_freight',
            'unique_orders', 'unique_products'
        ]
        
        return sales_metrics.reset_index()
    
    def _build_satisfaction_features(self):
        """æ„å»ºå®¢æˆ·æ»¡æ„åº¦ç‰¹å¾"""
        logger.info("   â­ æ„å»ºå®¢æˆ·æ»¡æ„åº¦æŒ‡æ ‡...")
        
        orders = self.raw_data['orders']
        order_items = self.raw_data['order_items']
        reviews = self.raw_data['reviews']
        
        # åˆå¹¶è¯„ä»·æ•°æ®
        order_details = order_items.merge(orders, on='order_id', how='left')
        order_reviews = order_details.merge(reviews, on='order_id', how='left')
        
        # åŸºç¡€è¯„ä»·æŒ‡æ ‡
        review_metrics = order_reviews.groupby('seller_id').agg({
            'review_score': ['mean', 'count', 'std'],
            'review_id': 'count'
        }).round(2)
        
        review_metrics.columns = ['avg_review_score', 'review_count', 'review_score_std', 'total_reviews']
        
        # å·®è¯„ç‡è®¡ç®—
        bad_reviews = order_reviews[order_reviews['review_score'] <= 2].groupby('seller_id').size()
        total_reviews = order_reviews.groupby('seller_id')['review_score'].count()
        bad_review_rate = (bad_reviews / total_reviews * 100).fillna(0).round(2)
        
        review_metrics['bad_review_rate'] = bad_review_rate
        
        return review_metrics.reset_index()
    
    def _build_efficiency_features(self):
        """æ„å»ºè¿è¥æ•ˆç‡ç‰¹å¾"""
        logger.info("   âš¡ æ„å»ºè¿è¥æ•ˆç‡æŒ‡æ ‡...")
        
        orders = self.raw_data['orders']
        order_items = self.raw_data['order_items']
        
        order_details = order_items.merge(orders, on='order_id', how='left')
        
        # è½¬æ¢æ—¶é—´å­—æ®µ
        time_cols = ['order_purchase_timestamp', 'order_delivered_carrier_date', 'order_delivered_customer_date']
        for col in time_cols:
            if col in order_details.columns:
                order_details[col] = pd.to_datetime(order_details[col], errors='coerce')
        
        # è®¡ç®—æ—¶é•¿æŒ‡æ ‡
        if 'order_delivered_carrier_date' in order_details.columns:
            order_details['shipping_days'] = (
                order_details['order_delivered_carrier_date'] - 
                order_details['order_purchase_timestamp']
            ).dt.days
        
        if 'order_delivered_customer_date' in order_details.columns:
            order_details['delivery_days'] = (
                order_details['order_delivered_customer_date'] - 
                order_details['order_delivered_carrier_date']
            ).dt.days
        
        # æŒ‰å–å®¶èšåˆè¿è¥æŒ‡æ ‡
        ops_metrics = order_details.groupby('seller_id').agg({
            'shipping_days': ['mean', 'median'],
            'delivery_days': ['mean', 'median'], 
            'order_status': lambda x: (x == 'delivered').sum() / len(x) * 100
        }).round(2)
        
        ops_metrics.columns = [
            'avg_shipping_days', 'median_shipping_days',
            'avg_delivery_days', 'median_delivery_days', 
            'delivery_success_rate'
        ]
        
        return ops_metrics.reset_index()
    
    def _build_category_features(self):
        """æ„å»ºäº§å“å“ç±»ç‰¹å¾"""
        logger.info("   ğŸ¯ æ„å»ºå“ç±»è¦†ç›–æŒ‡æ ‡...")
        
        order_items = self.raw_data['order_items']
        products = self.raw_data['products']
        
        # åˆå¹¶äº§å“ä¿¡æ¯
        product_details = order_items.merge(products, on='product_id', how='left')
        
        category_metrics = product_details.groupby('seller_id').agg({
            'product_category_name': 'nunique',
            'product_id': 'nunique'
        })
        
        category_metrics.columns = ['category_count', 'sku_count']
        
        return category_metrics.reset_index()
    
    def _build_temporal_features(self):
        """æ„å»ºæ—¶é—´è¶‹åŠ¿ç‰¹å¾"""
        logger.info("   ğŸ“… æ„å»ºæ—¶é—´è¶‹åŠ¿æŒ‡æ ‡...")
        
        orders = self.raw_data['orders']
        order_items = self.raw_data['order_items']
        
        order_details = order_items.merge(orders, on='order_id', how='left')
        order_details['order_purchase_timestamp'] = pd.to_datetime(
            order_details['order_purchase_timestamp'], errors='coerce'
        )
        
        # æ—¶é—´æŒ‡æ ‡
        time_metrics = order_details.groupby('seller_id')['order_purchase_timestamp'].agg([
            'min', 'max', 'count'
        ])
        time_metrics.columns = ['first_order_date', 'last_order_date', 'total_orders']
        
        # æ´»è·ƒå¤©æ•°å’Œè®¢å•é¢‘ç‡
        time_metrics['active_days'] = (
            time_metrics['last_order_date'] - time_metrics['first_order_date']
        ).dt.days + 1
        
        time_metrics['order_frequency'] = (
            time_metrics['total_orders'] / time_metrics['active_days']
        ).round(4)
        
        return time_metrics.reset_index()
    
    def _clean_and_derive_features(self, df):
        """æ•°æ®æ¸…æ´—å’Œè¡ç”Ÿç‰¹å¾è®¡ç®—"""
        logger.info("   ğŸ§¹ æ•°æ®æ¸…æ´—å’Œç‰¹å¾è¡ç”Ÿ...")
        
        # å¡«å……ç¼ºå¤±å€¼
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].fillna(0)
        
        # è¡ç”Ÿç‰¹å¾
        df['revenue_per_order'] = df['total_gmv'] / df['unique_orders'].replace(0, 1)
        df['items_per_order'] = df['total_items'] / df['unique_orders'].replace(0, 1)
        df['is_active'] = (df['total_gmv'] > 0).astype(int)
        
        return df
    
    def save_processed_data(self, filepath='data/seller_profile_processed.csv'):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        if self.seller_profile is not None:
            self.seller_profile.to_csv(filepath, index=False)
            logger.info(f"âœ… å·²ä¿å­˜åˆ°: {filepath}")
        else:
            logger.warning("âŒ æ²¡æœ‰å¤„ç†åçš„æ•°æ®å¯ä¿å­˜")
    
    def get_data_summary(self):
        """è·å–æ•°æ®æ‘˜è¦ä¿¡æ¯"""
        if self.seller_profile is None:
            return "å°šæœªæ„å»ºå–å®¶ç”»åƒæ•°æ®"
            
        active_sellers = self.seller_profile[self.seller_profile['is_active'] == 1]
        
        summary = {
            'total_sellers': len(self.seller_profile),
            'active_sellers': len(active_sellers),
            'total_gmv': active_sellers['total_gmv'].sum(),
            'total_orders': active_sellers['unique_orders'].sum(),
            'avg_rating': active_sellers['avg_review_score'].mean(),
            'features_count': len(self.seller_profile.columns)
        }
        
        return summary

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®ç®¡é“ä½¿ç”¨"""
    # åˆå§‹åŒ–æ•°æ®ç®¡é“
    pipeline = DataPipeline()
    
    # æ„å»ºå–å®¶ç‰¹å¾ç”»åƒ
    seller_profile = pipeline.build_seller_features()
    
    # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
    print("\nğŸ¯ æ•°æ®ç®¡é“æ‰§è¡Œç»“æœ:")
    print(f"  ğŸ“Š å¤„ç†åçš„å–å®¶æ•°é‡: {len(seller_profile):,}")
    print(f"  ğŸ“‹ ç‰¹å¾æ•°é‡: {len(seller_profile.columns)}")
    print(f"  ğŸ¯ æ´»è·ƒå–å®¶: {(seller_profile['is_active'] == 1).sum():,}")
    print(f"  ğŸ’° å¹³å°æ€»GMV: R$ {seller_profile['total_gmv'].sum():,.2f}")
    
    return seller_profile

if __name__ == "__main__":
    main() 